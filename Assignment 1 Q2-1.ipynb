{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Name: AG xx.\n",
    "\n",
    "Student Name (Student ID):\n",
    "\n",
    "1. xxxx xxxxx (xxxxxxx)\n",
    "\n",
    "2. xxxx xxxxx (xxxxxxx)\n",
    "\n",
    "3. xxxx xxxxx (xxxxxxx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yZOz6Y_cLGOT"
   },
   "source": [
    "# Question 2\n",
    "\n",
    "## Introduction to question 2\n",
    "\n",
    "In the second question of this assignment, we will explore the use of local search in genome assembly.\n",
    "\n",
    "We will use local search to assemble (construct) a large part of the nucleotide sequence of the monkeypox virus, which has been downloaded from the National Center for Biotechnology Information in the United States. Please note that no additional or specialized knowledge of biology or bioinformatics is required for this assignment. (Actechnical specifics of bioinformatics have been adapted and simplified for the purposes of this computer science assignment, so if you are a biologist, please do not apply preexisting knowledge to solve the problem. Furthermore, you should not attempt to search up the genome on genomic databases to \"guess\" the actual sequence, since we are more interested in your coding methodology rather than your attempts at reproducing a known sequence.)\n",
    "\n",
    "This is an introductory computer science assignment and not a bioinformatics assignment; we are simply using bioinformatics as a use case to illustrate the applicability of local search to the natural sciences. Therefore, no knowledge of bioinformatics is assumed or required. In the paragraphs that follow, I will give a short crash course which will cover all the domain knowledge you will need to know in order to tackle this problem.  \n",
    "\n",
    "For technical reasons, when we analyze the nucleotide sequence (genome) of a virus, we usually cannot “read” it in one fell swoop. We have to read the genome in parts, because the genome is usually too long for the machine to read in a single sitting. To simplify things, a “read” is a single view of part of the genome; think of it as a SUBSTRING, a partial view of the whole genome. After we have generated multiple reads of a genome, we then have to “stitch”, or combine, the different reads of the genome together. This process of stitching up reads of a genome into the final sequence is known as genome assembly. However, the different reads of the genome cannot just be concatenated like usual string concatenation. It’s not a situation where you have one read, “Hello”, and another read, “World”, and all you need to do is concatenate both strings together to make “Hello World”. Among other reasons, there are two major reasons why you can’t do so:\n",
    "\n",
    "1. You do not know which read came first. The reads are not ordered. How do you know “Hello” came after “World”? The answer is that you don’t. Imagine how complicated this situation might be if you had more than two reads. (This is indeed our situation, where we have $n$ reads, and $n>>2$.)\n",
    "\n",
    "2. One read may contain a substring contained in another read. Specifically, without loss of generality, part of the ending $x$ characters of a read (i.e., suffix) might also be found in the starting $x$ positions (i.e., prefix) of another read.\n",
    "\n",
    "- A computer scientist usually creates opportunities from problems. While this may be a “problem” in that you just can’t concatenate two strings blindly, the fact that strings contain shared “substrings” is actually a very helpful clue that you can use to “join” strings together. \n",
    "\n",
    "- Note that the choice of the value of $x$ could be a hyperparameter decided by the computer scientist.\n",
    "\n",
    "## Your tasks\n",
    "\n",
    "In this part of the assignment, you will work with (simulated) reads that I have generated from the nucleotide sequence of the monkeypox virus. In reality, bioinformatics is far more complicated, but here we will work with a simplified situation. Your task is to examine the reads that I have provided for you, and from there “infer” the nucleotide sequence that might have produced those reads. \n",
    "\n",
    "The reads are provided in the csv file `data.csv` which simply provides a list of unique strings. Note that you should NOT assume any particular ordering of the strings in this dataframe. In fact, the strings have already been shuffled randomly. \n",
    "\n",
    "NOTE: You are not allowed to use `pandas` or any other libraries apart from the Python STL to load the csv file.\n",
    "\n",
    "### Task A (3 marks): \n",
    "\n",
    "Create a directed graph. The nodes in the graph are the strings in the list of reads. An edge should be drawn FROM read A TO read B if and only if a suffix (of length $x$) of read A is also a prefix (obviously, also of length $x$) of read B. For the purposes of the assignment, limit the value of $x$ to between 5 and 30, both inclusive. That is, to be clear, $5\\leq x\\leq 30$. The weight of an edge between read A and read B should be the NEGATED value of $x$, i.e. $-x$. \n",
    "\n",
    "In your Jupyter notebook, please report the number of edges in your graph. Provide a barplot or histogram which shows the number of edges with different weights or weight categories. In this task, you are free to use plotting libraries such as `matplotlib` or `seaborn` to plot this graph.\n",
    "\n",
    "As an example, if read A is \"TACTAGT\" and read B is \"TAGTCCCCT\", then an edge is drawn FROM read A TO read B (i.e., $A \\rightarrow B$) with weight of $-4$. This is because the 4-suffix \"TAGT\" is also the 4-prefix of read B; in other words, the last 4 characters of read A (a substring of length 4) overlap with the first 4 characters of read B (a substring of length 4).\n",
    "\n",
    "### Task B (7 marks): \n",
    "\n",
    "From Task A, you now have a graph which shows connections between reads based on how they overlap, in theory you could draw a path through the graph and thereby derive the full sequence (genome).\n",
    "\n",
    "Task B asks you to use local search method(s) to determine a path through this directed graph of strings. \n",
    "\n",
    "- You are expected to use simulated annealing and tune the relevant configuration settings and hyperparameters. The minimum requirement is to implement simulated annealing.\n",
    "\n",
    "- Explain tha rationale behind the choice of scheduling strategy and parameters.\n",
    "\n",
    "- However, you may also explore other search methods in addition to simulated annealing. Marks will be awarded for effort.\n",
    "\n",
    "Note the following constraints:\n",
    "\n",
    "1. The path has to go through each and every vertex exactly once. For computer scientists, this constraint is reminiscent of the \"Traveling Salesman's Problem\", except that unlike TSP, we should not need to go back to the starting vertex again. \n",
    "\n",
    "2. For the purposes of neighbor generation / action selection at each node, bear in mind that a path through the graph which minimizes the total number of nucleotides in the assembled sequence is the preferred path. To state that another way, the assembled sequence should be derived from a path that goes through EACH and EVERY vertex exactly once, however we want this assembled sequence to be AS SHORT AS POSSIBLE.\n",
    "\n",
    "3. You are not given the starting (source/origin) or ending (destination) vertex.\n",
    "\n",
    "4. For avoidance of ambiguity, no cycles are allowed. You must not visit a vertex more than once.\n",
    "\n",
    "5. You are not allowed to use any libraries apart from the Python Standard Library.\n",
    "No import statements which import libraries outside of the Python STL should be found within your answer for Task B.\n",
    "\n",
    "Please remember to report the assembled sequence that you obtain. Although it would be great if you can come up with a good sequence, please feel reassured that we are more interested in your APPROACH to the problem, and so you can potentially get a reasonable score on this task even if your solution is \"wrong\". It is the process, rather than the result, which matters more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enironment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e0833561\\OneDrive - National University of Singapore\\Desktop\\it5005-proj-1\\AI-searching-team-proj\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\e0833561\\OneDrive - National University of Singapore\\Desktop\\it5005-proj-1\\AI-searching-team-proj\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "dna_fragments_list = []\n",
    "with open('./data/data.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            # print(f'Column names are {\", \".join(row)}')\n",
    "            pass\n",
    "            line_count += 1\n",
    "        else:\n",
    "            # print(f'\\t{row[0]} works in the {row[1]} department, and was born in {row[2]}.')\n",
    "            dna_fragments_list.append(row[2])\n",
    "            # line_count += 1\n",
    "    print(f'{dna_fragments_list[:2]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A outline\n",
    "\n",
    "### Pseudo-algorithm\n",
    "1. Start from arbitrary state\n",
    "    - Simply start from read order\n",
    "2. Nodes are `dna_fragments`.\n",
    "3. Can think of directed edges as pointing towards the next node, or in the words of the hint, from postfix to prefix.\n",
    "4. Initialize directed edges from $i$ to $i + 1$.\n",
    "5. Relax the constraint that $5 <= x <= 30$, where $x$ is number of letters that overlap.\n",
    "    - Constraint becomes $0 <= x$ which is satisfied by any graph.\n",
    "6. Think of actual cost we are trying to minimize as the total lengths of the joined substring, which is the sum of lengths of individual segments minum sum of lengths of overlaps (count each overlap only once).\n",
    "7. For the \"random flip\" analogy of crystallization, we do the following:\n",
    "    1. Generate a candidate change \n",
    "        1. Check if constraint satisfied. If not, generate another candidate change.\n",
    "    2. Check if heuristic cost of sum of $x$ decreases.\n",
    "        - if cost decreases: accept\n",
    "        - if cost does not decrease, accept with probability given by the temperature equation\n",
    "    \n",
    "\n",
    "\n",
    "### Implementation Specific Tasks\n",
    "0. I Think the framework of `class Problem` is couched in the terminology of an uninformed tree search (tree search in the sense we do not have to check for whether node is reached before.). But in this framework, the node is the entire state (includes both node of `dna_fragment` and edges of dna fragment overlaps.)\n",
    "1.In `__init__()`. initialize state we wish to keep track of.\n",
    "    - Nodes: list of strings representing DNA fragments.\n",
    "        - Use enumerate to generate id automatically. Treat the list as immutable.\n",
    "    - Edges: \n",
    "        - Option 1: list of tuples in the format (from_index, to_index, x) like adjacency list in graph algorithms\n",
    "        - Option 2: just join them up with double-linked lists, with the next pointer as the one referred to in the notebook hint, but the backlink for tracking predecessor.\n",
    "        - Suppose we go with Option 2 for simplicity and explicitness.\n",
    "2. In `actions`, we generate candidate change. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oBnbZpd2bt1N"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# Problem Class\n",
    "class Problem:\n",
    "    \"\"\"The abstract class for a formal problem. A new domain subclasses this,\n",
    "    overriding `actions` and `results`, and perhaps other methods.\n",
    "    The default heuristic is 0 and the default action cost is 1 for all states.\n",
    "    When you create an instance of a subclass, specify `initial`, and `goal` states \n",
    "    (or give an `is_goal` method) and perhaps other keyword args for the subclass.\"\"\"\n",
    "\n",
    "    def __init__(self, initial=None, goal=None, **kwds): \n",
    "        self.__dict__.update(initial=initial, goal=goal, **kwds) \n",
    "        \n",
    "    def actions(self, state):        raise NotImplementedError\n",
    "    def result(self, state, action): raise NotImplementedError\n",
    "    def is_goal(self, state):        return state == self.goal\n",
    "    def action_cost(self, s, a, s1): return 1\n",
    "    def h(self, node):               return 0\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({!r}, {!r})'.format(\n",
    "            type(self).__name__, self.initial, self.goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# Use the following Node class to generate search tree\n",
    "import math\n",
    "class Node:\n",
    "    \"A Node in a search tree.\"\n",
    "    def __init__(self, state, parent=None, action=None, path_cost=0):\n",
    "        self.__dict__.update(state=state, parent=parent, action=action, path_cost=path_cost)\n",
    "\n",
    "    def __repr__(self): return '<{}>'.format(self.state)\n",
    "    def __len__(self): return 0 if self.parent is None else (1 + len(self.parent))\n",
    "    def __lt__(self, other): return self.path_cost < other.path_cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2-y3Nt9ccxj"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# Code to generate neighbours, value of states, etc.\n",
    "class TSP(Problem):\n",
    "    def __init__(self, graph, csvpath, initial=None, goal=None, **kwds):\n",
    "        super().__init__(initial, goal, **kwds)\n",
    "        self.graph= graph\n",
    "        self.csvpath= csvpath\n",
    "        self.initial= self.generate_initial_state(self.graph)\n",
    "\n",
    "    \n",
    "    \n",
    "    def generate_initial_state(self,graph_dictionary):\n",
    "        # This function takes graph dictionary, and returns a complete tour with greedy selection\n",
    "        initial_state=[]\n",
    "    \n",
    "        #start with read 0\n",
    "        current_read= 0\n",
    "        reached_read=[]\n",
    "\n",
    "        initial_state.append(current_read)\n",
    "        reached_read.append(current_read)\n",
    "\n",
    "        while True:\n",
    "\n",
    "            #create temp list with format [(224, -16),(302, -5)], where current read can go to read 224 with -16 weight, 302 with -5 weight, etc       \n",
    "            temp_list=[]\n",
    "\n",
    "            # Cycle through all connections to a read, and output in a temporary list\n",
    "            for key in graph_dictionary:\n",
    "                if key[0]== current_read:\n",
    "                # cycle through all weights (if more than 1) between 1 edge \n",
    "                    for i in graph_dictionary[key]:\n",
    "                        temp_list.append((key[1],i))\n",
    "\n",
    "\n",
    "            #*****TRACING******\n",
    "            print(temp_list)\n",
    "\n",
    "\n",
    "            # Out of all the edges, find the minimum edge in a greedy way for the initial stage. \n",
    "            min_weight=((0,10000))\n",
    "\n",
    "            for element in temp_list:\n",
    "                # Check if the next read is not already reached. \n",
    "                if element[0] not in reached_read:\n",
    "                    if element[1]<min_weight[1]:\n",
    "                        min_weight=((element[0],element[1]))\n",
    "\n",
    "            # If a read has no other neighbour, go to the first unreached read with weight 0.\n",
    "            if min_weight[0]==0 and min_weight[1]==10000:\n",
    "                for i in range(0, number_of_reads):\n",
    "                    if i not in reached_read:\n",
    "                        min_weight=(i,0)\n",
    "                        break\n",
    "\n",
    "            #*****TRACING******        \n",
    "            print(f\"Read {current_read} goes to {min_weight[0]} with weight {min_weight[1]}\")\n",
    "\n",
    "            initial_state.append(min_weight[0])\n",
    "            reached_read.append(min_weight[0])\n",
    "            temp_list.clear()        \n",
    "\n",
    "            # Check if we reached all elements, if yes, stop the loop. If no, continue loop\n",
    "            if len(reached_read)==number_of_reads:\n",
    "                break\n",
    "            else:\n",
    "                current_read=min_weight[0]\n",
    "\n",
    "\n",
    "        print(f\"The initial state is {initial_state}\")\n",
    "\n",
    "        print(initial_state)\n",
    "                \n",
    "        return initial_state\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    def get_weight_between_two_reads(self,testing_tuple):\n",
    "        # This function checks the graph for the weights between 2 reads, and takes the most negative\n",
    "        if testing_tuple in self.graph.keys():\n",
    "            setofweights= self.graph[testing_tuple]\n",
    "            #There could be more than 1 edge between 2 reads, pick most negative\n",
    "            return min(setofweights)\n",
    "        else:\n",
    "            #If there is no edge between 2 reads, assume weight is 0\n",
    "            return 0\n",
    "        \n",
    "        \n",
    "    \n",
    "    def value_of_state(self,state):\n",
    "        # This function takes a state- a complete tour eg [1,20,3,5,7,9,200...]\n",
    "        # and returns the value of the entire tour, which is the sum of all the weights\n",
    "        # This is done by checking the graph for the weights between 2 reads, and taking the most negative\n",
    "        \n",
    "        valuecounter=0 \n",
    "        \n",
    "        for i in range(len(state)):\n",
    "            if i+1<len(state):\n",
    "                testing_tuple=((state[i],state[i+1]))\n",
    "                valuecounter+=self.get_weight_between_two_reads(testing_tuple)\n",
    "        \n",
    "        return valuecounter\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def generate_genome_sequence(self,state):\n",
    "        # This function takes a state- a complete tour eg [1,20,3,5,7,9,200...]\n",
    "        # and returns a) The complete stitched string, with overlaps merged\n",
    "        # and b) The length of the completed stitched string\n",
    "\n",
    "        temparray=[]\n",
    "        genome_sequence=\"\"\n",
    "    \n",
    "        with open(self.csvpath) as f:\n",
    "            f.readline()\n",
    "            counter=0\n",
    "            for line in f:\n",
    "                list_form=line.rstrip('\\n').split(',')\n",
    "                temparray.append([list_form[0]])\n",
    "                temparray[counter].append(list_form[2])\n",
    "                counter+=1\n",
    "               \n",
    "        for i in range(len(state)):\n",
    "            if i+1<len(state):\n",
    "                testing_tuple=((state[i],state[i+1]))\n",
    "\n",
    "                weight=self.get_weight_between_two_reads(testing_tuple)\n",
    "\n",
    "                if weight!=0:\n",
    "                    genome_sequence+=temparray[state[i]][1][:weight]\n",
    "                else:\n",
    "                    genome_sequence+=temparray[state[i]][1]\n",
    "                    \n",
    "                \n",
    "        return genome_sequence, len(genome_sequence)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_neighbour(self,state):\n",
    "        # This function takes a state- a complete tour eg [1,20,3,5,7,9,200...]\n",
    "        # It goes through the 2-Opt method\n",
    "        # and returns a neighbouring state- another complete tour, eg [1,20,9,5,7,...]\n",
    "        \n",
    "\n",
    "        #TODO\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# STEP 1: GENERATE THE GRAPH AND INITIALISE THE PROBLEM \n",
    "\n",
    "\n",
    "# 1a: Function for taking in the CSV file, and output graph in dictionary \n",
    "# Dictionary has a format of example {(0, 1):{-20,-5-6}}, where 0 has an edge to 1, with weights of -20, -5 and -6. \n",
    "csvpath='q2 testing/dummy.csv'\n",
    "\n",
    "def readcsvfile(filename):\n",
    "    temparray=[]\n",
    "    outputgraph={}\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        f.readline()\n",
    "        counter=0\n",
    "        for line in f:\n",
    "            list_form=line.rstrip('\\n').split(',')\n",
    "            temparray.append([list_form[0]])\n",
    "            temparray[counter].append(list_form[2])\n",
    "            counter+=1\n",
    "    \n",
    "    for i in range(len(temparray)):\n",
    "        currentindex=temparray[i][0]\n",
    "        currentreadsequence=temparray[i][1]\n",
    "        \n",
    "        for m in range(len(temparray)):\n",
    "            if i==m:\n",
    "                continue\n",
    "  \n",
    "            for k in range(2,20):\n",
    "                testingreadsequence=temparray[m][1]\n",
    "\n",
    "                if currentreadsequence[-k:]==testingreadsequence[0:k]:\n",
    "                    if outputgraph.get((i,m),'error not found') != 'error not found':\n",
    "                        outputgraph[(i,m)].add(-k)\n",
    "                        \n",
    "                    else:\n",
    "                        outputgraph[(i,m)]={-k}\n",
    "\n",
    "    #print(counter)\n",
    "    return(outputgraph, counter)\n",
    "    \n",
    "graph_dictionary, number_of_reads= readcsvfile(csvpath)\n",
    "print(graph_dictionary)\n",
    "\n",
    "\n",
    "\n",
    "# 1b: Initialise the Problem TSP Class with the graph, and the path to the CSV (used for stitching at the end).\n",
    "# Initial state is immediately generated by the generate_initial_state method in the TSP Class\n",
    "\n",
    "tsp=TSP(graph_dictionary, csvpath)\n",
    "\n",
    "\n",
    "\n",
    "# 1c: Test and check the value of initial state. \n",
    "\n",
    "value_of_state= tsp.value_of_state(tsp.initial)\n",
    "\n",
    "print(f\"The value of the initial state is {value_of_state}\")\n",
    "\n",
    "\n",
    "\n",
    "# 1d: Test and check the sequence created by the initial state. \n",
    "\n",
    "stitched_string, length_stitched= tsp.generate_genome_sequence(tsp.initial)\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(f\"The length of the stitched genone of the initial state is {length_stitched}\")\n",
    "print(f\"The stitched genome is\")\n",
    "print(stitched_string)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": [
    "# STEP 2: START SIMULATED ANNEALING\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://localhost:8888/'. Verify the server is running and reachable. (request to http://localhost:8888/api/kernels?1664028111628 failed, reason: connect ECONNREFUSED 127.0.0.1:8888)."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
